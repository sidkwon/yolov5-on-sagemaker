{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b394c9e",
   "metadata": {},
   "source": [
    "# SageMaker에서 YOLOv5 학습\n",
    "\n",
    "**References**\n",
    "> YOLOv5: https://github.com/ultralytics/yolov5  \n",
    "> Amazon SageMaker를 이용한 시계열 학습과 MLOps 구성: https://github.com/Napkin-DL/sm-informer-mlops-quicksight  \n",
    "> How to Train YOLOv5 On a Custom Dataset: https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/\n",
    "\n",
    "**Kernel:** `conda_pytorch_latest_p36`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293106e",
   "metadata": {},
   "source": [
    "## 1. 필요한 패키지 설치 및 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ba9fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7dff35",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (2.68.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.1.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.19.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (3.19.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (4.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (21.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (21.2.0)\n",
      "Requirement already satisfied: docker-compose>=1.25.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: docker==5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.0.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: urllib3!=1.25,!=1.25.1,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.26.7)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (0.59.0)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.26.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (1.22.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.32->sagemaker[local]) (2.8.2)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.19.1)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.0)\n",
      "Requirement already satisfied: cached-property<2,>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.5.2)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.8.0)\n",
      "Requirement already satisfied: six>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from dockerpty<1,>=0.4.1->docker-compose>=1.25.2->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.10.0.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (58.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker[local]) (3.0.1)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (35.0.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.4.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (2.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (3.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->sagemaker[local]) (2021.3)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sagemaker-experiments in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (0.1.35)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-experiments) (1.19.3)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.22.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (2.68.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (4.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (21.0)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.19.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (3.19.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.22.3)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.32->sagemaker) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.32->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (3.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "nvidia-docker2 already installed. We are good to go!\n",
      "Stopping docker: \u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "Starting docker:\t.\u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U 'sagemaker[local]'\n",
    "    !{sys.executable} -m pip install -U sagemaker-experiments # SageMaker Experiments SDK \n",
    "    !{sys.executable} -m pip install -U sagemaker             # SageMaker Python SDK\n",
    "    !/bin/bash ./local/local_mode_setup.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a39fff",
   "metadata": {},
   "source": [
    "## 2. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84bc4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "# import splitfolders\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import strftime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864a783",
   "metadata": {},
   "source": [
    "## 3. SageMaker Experiments 설정\n",
    "[SageMaker Experiments](https://aws.amazon.com/blogs/machine-learning/streamline-modeling-with-amazon-sagemaker-studio-and-amazon-experiments-sdk/)는 기계 학습 실험을 구성, 추적, 비교 및 평가할 수 있는 Amazon SageMaker 의 기능입니다. 기계 학습은 반복적인 프로세스입니다. 점진적인 변화가 모델 정확도에 미치는 영향을 관찰하면서 데이터, 알고리즘 및 파라미터의 여러 조합을 이용해 실험을 해야 합니다. 시간이 지남에 따라 실험이 반복되면서 수천 개의 모델 훈련 및 모델 버전이 생성될 수 있습니다. 따라서 최고의 성과를 보이는 모델과 입력 구성을 추적하기가 어렵습니다. 또한 현재 진행 중인 실험을 이전의 실험과 비교하여 추가적이고 점진적인 개선 기회를 찾아내는 것도 어렵습니다.\n",
    "\n",
    "SageMaker Experiments는 반복 작업의 입력, 파라미터, 구성 및 결과를재판. 이러한 시도를 실험으로 할당하고 그룹화 및 구성할 수 있습니다. SageMaker 실험은 Amazon SageMaker 스튜디오와 통합되어 현재 진행 중인 실험과 과거 실험을 탐색하고, 주요 성과 지표를 토대로 시도를 비교하며, 최고의 성과를 보이는 모델을 식별하기 위한 시각적 인터페이스를 제공합니다.\n",
    "\n",
    "SageMaker Experiments는 Experiment, Trial, Trial Component, Tracker로 구성되어 있습니다. 각 구성요소의 관계는 아래 그림을 참조하세요.\n",
    "\n",
    "<p align=\"center\">\n",
    "<center><img src=\"./image/sm-experiments.jpeg\" height=\"400\" width=\"600\" alt=\"\"><center>\n",
    "<br><br>\n",
    "<b>Figure 1.SageMaker Experiments 구성요소</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb4fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                          tags=[\n",
    "                                              {\n",
    "                                                  'Key': 'modelname',\n",
    "                                                  'Value': 'yolov5_sm'\n",
    "                                              },\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f01001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, set_param, i_type, i_cnt, spot):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    \n",
    "    algo = 'dp'\n",
    "    \n",
    "    spot = 's' if spot else 'd'\n",
    "    i_tag = 'test'\n",
    "    \n",
    "    if i_type == 'ml.p3.16xlarge':\n",
    "        i_tag = 'p3'\n",
    "    elif i_type == 'ml.p2.8xlarge':\n",
    "        i_tag = 'p2'\n",
    "    elif i_type == 'ml.p3dn.24xlarge':\n",
    "        i_tag = 'p3dn'\n",
    "    elif i_type == 'ml.p4d.24xlarge':\n",
    "        i_tag = 'p4d'    \n",
    "        \n",
    "    trial = \"-\".join([i_tag,str(i_cnt),algo, spot])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47407f03",
   "metadata": {},
   "source": [
    "## 4. 데이터 저장소와 학습 script 위치 설정  \n",
    ">[Using the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html)  \n",
    ">[Session](https://sagemaker.readthedocs.io/en/stable/api/utility/session.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601af7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sinjoonk/yolov5'\n",
    "\n",
    "sess = boto3.Session() \n",
    "sagemaker_session = sagemaker.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "s3_data_path = f's3://{default_bucket}/{prefix}'\n",
    "source_dir = 'yolov5' # Folder name having training codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa060934",
   "metadata": {},
   "source": [
    "## 5. yolov5 format 데이터 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b326c5f",
   "metadata": {},
   "source": [
    "실습에 사용한 데이터셋은 [roboflow 에서 공개한 BCCD Dataset](https://public.roboflow.com/object-detection/bccd)으로, 혈액의 WBC(백혈구), RBC(적혈구), Platelets(혈소판)를 촬영한 이미지들입니다.\n",
    "\n",
    "yolov5 object detection모델을 학습하기 위한 train/val/test 데이터셋은 다음과 같은 폴더 구조를 따라야 합니다. `images` 폴더에는 이미지를 저장하고, `labels` 폴더에는 이미지 별 annotation 결과 파일을 저장합니다.\n",
    "```\n",
    "├── test\n",
    "│   ├── images\n",
    "│   └── labels\n",
    "├── train\n",
    "│   ├── images\n",
    "│   └── labels\n",
    "└── valid\n",
    "    ├── images\n",
    "    └── labels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04fa377",
   "metadata": {},
   "source": [
    "YOLOv5에서는 데이터셋이 저장된 경로와 Class수, Class이름을 별도 YAML파일에 선언합니다. \n",
    "\n",
    "- `data_local.yaml`: 학습을 에서 수행할 경우 사용하는 설정 파일입니다.\n",
    "- `data_sm.yaml`: 학습을 SageMaker Local mode, SageMaker managed training에서 수행할 경우 사용하는 설정 파일입니다. SageMaker는 S3에 저장된 데이터셋을(managed training의 경우, Local mode에서는 Local에 저장된 데이터셋) SageMaker container 내 `/opt/ml/input/data/[channel_name]/` 에 저장하므로 `train`, `val` 경로는 Jupyter notebook local 경로가 아닌 SageMaker container의 경로를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b9dd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting yolov5/data/data_sm.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile yolov5/data/data_sm.yaml\n",
    "train: /opt/ml/input/data/yolov5_input/train/images\n",
    "val: /opt/ml/input/data/yolov5_input/valid/images\n",
    "\n",
    "nc: 3\n",
    "names: ['Platelets', 'RBC', 'WBC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0823fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting yolov5/data/data_local.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile yolov5/data/data_local.yaml\n",
    "train: BCCD/train/images\n",
    "val: BCCD/valid/images\n",
    "\n",
    "nc: 3\n",
    "names: ['Platelets', 'RBC', 'WBC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6aa4d",
   "metadata": {},
   "source": [
    "Jupyter notebook내 데이터셋을 S3에 업로드 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3af3ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-889750940888/sinjoonk/yolov5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9916d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync ./BCCD {s3_data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45fd6d",
   "metadata": {},
   "source": [
    "## 6. Configuration for Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853fbc2",
   "metadata": {},
   "source": [
    "### Experiments 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bab397",
   "metadata": {},
   "source": [
    "SageMaker managed training 수행 중 발생하는 output file들과 checkpoint를 저장할 S3경로를 지정합니다. Output은 학습 결과물인 **model artifacts, SageMaker debugger output, SageMaker debugger profiling output, SageMaker debugger rules output** 등을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2f2279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_location = f's3://{default_bucket}/{prefix}/sm_codes'\n",
    "output_path = f's3://{default_bucket}/{prefix}/output' \n",
    "checkpoint_s3_bucket = f's3://{default_bucket}/{prefix}/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5756874",
   "metadata": {},
   "source": [
    "### Debugger - Rules\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/pytorch_profiling/pt-resnet-profiling-single-gpu-single-node.ipynb\n",
    "\n",
    "- loss_not_decreasing: checks if loss is decreasing and triggers if the loss has not decreased by a certain persentage in the last few iterations\n",
    "- LowGPUUtilization: checks if GPU is under-utilizated\n",
    "- ProfilerReport: runs the entire set of performance rules and create a final output report with further insights and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f04edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827ead4",
   "metadata": {},
   "source": [
    "### Debugger - Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c933f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69675186",
   "metadata": {},
   "source": [
    "### Metric definitions 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c8127",
   "metadata": {},
   "source": [
    "학습코드 수행 시 발생하는 Standard output 로그에서 특정 패턴을 만족하는 값을 찾아 CloudWatch 사용자 metric으로 저장할 수 있습니다. `metric_definitions`는 SageMaker `Estimator`를 선언할 때 `metric_definitions` 파라미터의 값으로 전달 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16095f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "metric_definitions = [\n",
    "    {'Name': 'Precision', 'Regex': r'all\\s+[0-9.]+\\s+[0-9.]+\\s+([0-9.]+)'},\n",
    "    {'Name': 'Recall', 'Regex': r'all\\s+[0-9.]+\\s+[0-9.]+\\s+[0-9.]+\\s+([0-9.]+)'},\n",
    "    {'Name': 'mAP@.5', 'Regex': r'all\\s+[0-9.]+\\s+[0-9.]+\\s+[0-9.]+\\s+[0-9.]+\\s+([0-9.]+)'},\n",
    "    {'Name': 'mAP@.5:.95', 'Regex': r'all\\s+[0-9.]+\\s+[0-9.]+\\s+[0-9.]+\\s+[0-9.]+\\s+[0-9.]+\\s+([0-9.]+)'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e24cdf",
   "metadata": {},
   "source": [
    "## 7. 로컬에서 학습 코드 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca543b",
   "metadata": {},
   "source": [
    "### WandB 설정 (Optional)\n",
    "https://wandb.ai/cayush/yoloV5/reports/Track-and-debug-your-YOLOv5-models--VmlldzozMDQ1OTg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74bb485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f271690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python yolov5/train_sm.py \\\n",
    "# --batch-size 64 \\\n",
    "# --cfg yolov5s.yaml \\\n",
    "# --data data_local.yaml \\\n",
    "# --epochs 1 \\\n",
    "# --freeze 24 \\\n",
    "# --weights weights/yolov5s.pt \\\n",
    "# --workers 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb28882",
   "metadata": {},
   "source": [
    "`wandb.init()`을 수행하면 `/root/.netrc` 파일에 WEB API Key가 저장됩니다. `.netrc`파일을 SageMaker Local/Managed 학습 수행 시 실행되는 Container내부의 `/root/.netrc`로 저장하기 위한 코드를 `utils/loggers/__init__.py`에 추가합니다. `.netrc` 파일은 `source_dir/.netrc`에 미리 저장해야 합니다.\n",
    "\n",
    "```\n",
    "# __init__.py\n",
    "...\n",
    "################## For SageMaker ##################\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "### Thanks to Youngjoon Choi :)\n",
    "def wandb_setting():\n",
    "    set_path = '/opt/ml/code/.netrc' #WANDB API Key\n",
    "    file = Path(set_path)\n",
    "    if file.exists():\n",
    "        subprocess.run(['cp', '-r', set_path, '/root/.netrc'])\n",
    "    else:\n",
    "        print('=' * 100)\n",
    "        print('Not found!!!')\n",
    "        print('=' * 100)    \n",
    "\n",
    "wandb_setting()\n",
    "################## For SageMaker ##################\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a604438",
   "metadata": {},
   "source": [
    "## 8. Local mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae59c8",
   "metadata": {},
   "source": [
    "`yolo5/train_sm.py` 에 argument로 passing할 hyperparameter를 정의합니다. SageMaker에서 estimator를 만들 때 지정한 hyperparameter를 SageMaker container 내부의 `/opt/ml/input/config/hyperparameters.json`으로 저장하고 `train_sm.py` 코드를 수행할 때 `hyperparameters.json` 파일을 읽어 argument로 feeding합니다.\n",
    "\n",
    "Local mode에서는 `train_sm.py`가 SageMaker환경에서 오류 없이 수행 되는지를 확인하려는 목적이므로 `epochs`의 값을 `1`으로 지정합니다.\n",
    "\n",
    "학습 시 상대적으로 적은 이미지를 사용하므로 Transfer Learning 기법을 사용합니다.  \n",
    "- Transfer Learning with Frozen Layers: https://github.com/ultralytics/yolov5/issues/1314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9447c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_local = {\n",
    "    'data': 'data_sm.yaml',\n",
    "    'cfg': 'yolov5s.yaml',\n",
    "    'weights': 'weights/yolov5s.pt', # Transfer learning\n",
    "    'batch-size': 64,\n",
    "    'epochs': 1,\n",
    "    'project': '/opt/ml/model',\n",
    "    'workers': 0, # To avoid shm OOM issue\n",
    "    'freeze': 10, # For transfer learning, freeze all Layers except for the final output convolution layers.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8752db",
   "metadata": {},
   "source": [
    "SageMaker prebuilt Pytorch container이미지의 torch, torchvision버전을 각각 1.9.1+cu111, 0.10.1+cu111으로 재설치 할 수 있도록 `requirements.txt` 파일에 아래 항목을 추가합니다.\n",
    "\n",
    "```\n",
    "# requirements.txt\n",
    "...\n",
    "### For SageMaker\n",
    "--find-links https://download.pytorch.org/whl/torch_stable.html\n",
    "torch==1.9.1+cu111\n",
    "torchvision==0.10.1+cu111\n",
    "### For SageMaker\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b323d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "sagemaker_session = LocalSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a7af7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "\n",
    "estimator_local = PyTorch(\n",
    "    entry_point='train_sm.py',\n",
    "    source_dir=source_dir,\n",
    "    base_job_name='yolov5-on-sagemaker',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py36',\n",
    "    instance_count=1,\n",
    "    instance_type='local_gpu',\n",
    "    volume_size=256,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters_local,\n",
    "#     metric_definitions=metric_definitions,\n",
    "    max_run=3*60*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afcdc227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.dataset.txt  README.roboflow.txt  test  train  valid\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(os.getcwd(), 'BCCD')\n",
    "!ls {train_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb2e276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'yolov5_input': 'file://{}'.format(train_dir)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1583ad1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: yolov5-on-sagemaker-2021-11-08-12-23-24-937\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-m9v5w:\n",
      "    command: train\n",
      "    container_name: n076r1dscw-algo-1-m9v5w\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8.1-gpu-py36\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-m9v5w\n",
      "    runtime: nvidia\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpvjgav8jt/algo-1-m9v5w/input:/opt/ml/input\n",
      "    - /tmp/tmpvjgav8jt/algo-1-m9v5w/output:/opt/ml/output\n",
      "    - /tmp/tmpvjgav8jt/algo-1-m9v5w/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpvjgav8jt/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/yolov5-on-sagemaker/BCCD:/opt/ml/input/data/yolov5_input\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpvjgav8jt/docker-compose.yaml up --build --abort-on-container-exit\n",
      "INFO:sagemaker.local.image:docker command: docker pull 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8.1-gpu-py36\n",
      "INFO:sagemaker.local.image:image pulled: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8.1-gpu-py36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating n076r1dscw-algo-1-m9v5w ... \n",
      "Creating n076r1dscw-algo-1-m9v5w ... done\n",
      "Attaching to n076r1dscw-algo-1-m9v5w\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m 2021-11-08 12:23:32,025 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m 2021-11-08 12:23:32,049 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m 2021-11-08 12:23:32,052 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m 2021-11-08 12:23:33,076 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting torch==1.9.1+cu111\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp36-cp36m-linux_x86_64.whl (2041.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting torchvision==0.10.1+cu111\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp36-cp36m-linux_x86_64.whl (20.6 MB)\n",
      "     |████████████████████████████████| 20.6 MB 18.5 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting tensorboard>=2.4.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "     |████████████████████████████████| 5.8 MB 14.7 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting wandb\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 37.1 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 28)) (0.11.2)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting thop\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.9.1+cu111->-r requirements.txt (line 16)) (0.8)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.9.1+cu111->-r requirements.txt (line 16)) (3.10.0.2)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.10.1+cu111->-r requirements.txt (line 17)) (8.3.2)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision==0.10.1+cu111->-r requirements.txt (line 17)) (1.19.1)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting tensorboard-plugin-wit>=1.6.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 44.4 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting grpcio>=1.24.3\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading grpcio-1.41.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "     |████████████████████████████████| 3.9 MB 36.8 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting absl-py>=0.4\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 47.6 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 35.8 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 46.4 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (49.6.0.post20210108)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (0.36.2)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.0.2)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting markdown>=2.6.8\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 8.7 MB/s             \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (3.18.1)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.26.0)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (5.8.0)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (8.0.3)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting yaspin>=1.0.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (5.4.1)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting shortuuid>=0.5.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading shortuuid-1.0.2-py3-none-any.whl (8.0 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting GitPython>=1.0.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "     |████████████████████████████████| 170 kB 44.2 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting sentry-sdk>=1.0.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
      "     |████████████████████████████████| 139 kB 49.5 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting promise<3,>=2.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading promise-2.3.tar.gz (19 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (1.16.0)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (2.8.2)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting subprocess32>=3.5.3\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "     |████████████████████████████████| 97 kB 8.8 MB/s             \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting configparser>=3.8.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting pathtools\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hRequirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.6/site-packages (from seaborn>=0.11.0->-r requirements.txt (line 28)) (1.1.5)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.6/site-packages (from seaborn>=0.11.0->-r requirements.txt (line 28)) (1.5.4)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.6/site-packages (from seaborn>=0.11.0->-r requirements.txt (line 28)) (3.3.4)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from Click!=8.0.0,>=7.0->wandb->-r requirements.txt (line 24)) (4.8.1)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting gitdb<5,>=4.0.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "     |████████████████████████████████| 63 kB 2.1 MB/s             \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 47.6 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 23)) (4.7.2)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting requests-oauthlib>=0.7.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.0->-r requirements.txt (line 28)) (2.4.7)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.0->-r requirements.txt (line 28)) (0.10.0)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.0->-r requirements.txt (line 28)) (1.3.1)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23->seaborn>=0.11.0->-r requirements.txt (line 28)) (2021.3)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (1.26.6)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.10)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.0.4)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (2021.5.30)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting termcolor<2.0.0,>=1.1.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 23)) (0.4.8)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Collecting oauthlib>=3.0.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "     |████████████████████████████████| 146 kB 47.6 MB/s            \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb->-r requirements.txt (line 24)) (3.6.0)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Building wheels for collected packages: promise, subprocess32, pathtools, termcolor\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=b1ef0b4e112503c6734944b98bcc17e095efb37a6042e7f2669863079ccb567c\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6488 sha256=c561e0f7fa186787c44989c03ac4d885ec54464f1d4441d2cac26706f694e846\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/44/3a/ab/102386d84fe551b6cedb628ed1e74c5f5be76af8b909aeda09\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=cbfde6a6cf7b9fbe366daae261ed62f206f2f504b0a7fa177eff0a1dcbe6326f\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/42/ea/90/e37d463fb3b03848bf715080595de62545266f53dd546b2497\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=cc532dad97f2ed4e9ccc0f6616d1a2fcd0f2e253833fc2aa8e76383a9a76039e\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Successfully built promise subprocess32 pathtools termcolor\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Installing collected packages: smmap, pyasn1-modules, oauthlib, cachetools, termcolor, requests-oauthlib, google-auth, gitdb, yaspin, torch, tensorboard-plugin-wit, tensorboard-data-server, subprocess32, shortuuid, sentry-sdk, promise, pathtools, markdown, grpcio, google-auth-oauthlib, GitPython, docker-pycreds, configparser, absl-py, wandb, torchvision, thop, tensorboard\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Attempting uninstall: torch\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     Found existing installation: torch 1.8.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     Uninstalling torch-1.8.1:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m       Successfully uninstalled torch-1.8.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   Attempting uninstall: torchvision\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     Found existing installation: torchvision 0.9.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     Uninstalling torchvision-0.9.1:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m       Successfully uninstalled torchvision-0.9.1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Successfully installed GitPython-3.1.18 absl-py-0.15.0 cachetools-4.2.4 configparser-5.1.0 docker-pycreds-0.4.0 gitdb-4.0.9 google-auth-2.3.3 google-auth-oauthlib-0.4.6 grpcio-1.41.1 markdown-3.3.4 oauthlib-3.1.1 pathtools-0.1.2 promise-2.3 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 sentry-sdk-1.4.3 shortuuid-1.0.2 smmap-5.0.0 subprocess32-3.5.4 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 termcolor-1.1.0 thop-0.0.31.post2005241907 torch-1.9.1+cu111 torchvision-0.10.1+cu111 wandb-0.12.6 yaspin-2.1.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m 2021-11-08 12:26:17,382 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Training Env:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m {\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"yolov5_input\": \"/opt/ml/input/data/yolov5_input\"\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     },\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"current_host\": \"algo-1-m9v5w\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"algo-1-m9v5w\"\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     ],\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"data\": \"data_sm.yaml\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"cfg\": \"yolov5s.yaml\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"weights\": \"weights/yolov5s.pt\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"batch-size\": 64,\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"project\": \"/opt/ml/model\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"workers\": 0,\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"freeze\": 10\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     },\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"yolov5_input\": {\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         }\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     },\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"job_name\": \"yolov5-on-sagemaker-2021-11-08-12-23-24-937\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"master_hostname\": \"algo-1-m9v5w\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-889750940888/yolov5-on-sagemaker-2021-11-08-12-23-24-937/source/sourcedir.tar.gz\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"module_name\": \"train_sm\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"num_gpus\": 1,\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"current_host\": \"algo-1-m9v5w\",\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m             \"algo-1-m9v5w\"\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m         ]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     },\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m     \"user_entry_point\": \"train_sm.py\"\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m }\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Environment variables:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HOSTS=[\"algo-1-m9v5w\"]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HPS={\"batch-size\":64,\"cfg\":\"yolov5s.yaml\",\"data\":\"data_sm.yaml\",\"epochs\":1,\"freeze\":10,\"project\":\"/opt/ml/model\",\"weights\":\"weights/yolov5s.pt\",\"workers\":0}\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_USER_ENTRY_POINT=train_sm.py\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-m9v5w\",\"hosts\":[\"algo-1-m9v5w\"]}\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_INPUT_DATA_CONFIG={\"yolov5_input\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_CHANNELS=[\"yolov5_input\"]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_CURRENT_HOST=algo-1-m9v5w\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_MODULE_NAME=train_sm\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_NUM_GPUS=1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-889750940888/yolov5-on-sagemaker-2021-11-08-12-23-24-937/source/sourcedir.tar.gz\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"yolov5_input\":\"/opt/ml/input/data/yolov5_input\"},\"current_host\":\"algo-1-m9v5w\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-m9v5w\"],\"hyperparameters\":{\"batch-size\":64,\"cfg\":\"yolov5s.yaml\",\"data\":\"data_sm.yaml\",\"epochs\":1,\"freeze\":10,\"project\":\"/opt/ml/model\",\"weights\":\"weights/yolov5s.pt\",\"workers\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"yolov5_input\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"yolov5-on-sagemaker-2021-11-08-12-23-24-937\",\"log_level\":20,\"master_hostname\":\"algo-1-m9v5w\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-889750940888/yolov5-on-sagemaker-2021-11-08-12-23-24-937/source/sourcedir.tar.gz\",\"module_name\":\"train_sm\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-m9v5w\",\"hosts\":[\"algo-1-m9v5w\"]},\"user_entry_point\":\"train_sm.py\"}\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"64\",\"--cfg\",\"yolov5s.yaml\",\"--data\",\"data_sm.yaml\",\"--epochs\",\"1\",\"--freeze\",\"10\",\"--project\",\"/opt/ml/model\",\"--weights\",\"weights/yolov5s.pt\",\"--workers\",\"0\"]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_CHANNEL_YOLOV5_INPUT=/opt/ml/input/data/yolov5_input\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_DATA=data_sm.yaml\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_CFG=yolov5s.yaml\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_WEIGHTS=weights/yolov5s.pt\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_BATCH-SIZE=64\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_PROJECT=/opt/ml/model\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_WORKERS=0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m SM_HP_FREEZE=10\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m /opt/conda/bin/python3.6 train_sm.py --batch-size 64 --cfg yolov5s.yaml --data data_sm.yaml --epochs 1 --freeze 10 --project /opt/ml/model --weights weights/yolov5s.pt --workers 0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m ====================================================================================================\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m THIS IS train_sm.py!!!\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m torchvision version: 0.10.1+cu111\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m torch version: 1.9.1+cu111\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m ====================================================================================================\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Parse error at \"'--find-l'\": Expected W:(abcd...)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Plotting labels... \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.30, Best Possible Recall (BPR) = 0.9994\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Optimizer stripped from /opt/ml/model/exp/weights/last.pt, 14.5MB\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Optimizer stripped from /opt/ml/model/exp/weights/best.pt, 14.5MB\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Currently logged in as: annakie (use `wandb login --relogin` to force relogin)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1mtrain_sm: \u001b[0mweights=weights/yolov5s.pt, cfg=yolov5s.yaml, data=data_sm.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=1, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=0, project=/opt/ml/model, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=10, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, model_dir=/opt/ml/model\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m YOLOv5 🚀 2021-11-8 torch 1.9.1+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /opt/ml/model', view at http://localhost:6006/\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Tracking run with wandb version 0.12.6\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Syncing run yolov5-on-sagemaker-2021-11-08-12-23-24-937-algo-1-m9v5w\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: ⭐️ View project at https://wandb.ai/annakie/model\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: 🚀 View run at https://wandb.ai/annakie/model/runs/yolov5-on-sagemaker-2021-11-08-12-23-24-937-algo-1-m9v5w\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Run data is saved locally in /opt/ml/code/wandb/run-20211108_122631-yolov5-on-sagemaker-2021-11-08-12-23-24-937-algo-1-m9v5w\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Overriding model.yaml nc=80 with nc=3\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m                  from  n    params  module                                  arguments                     \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m   9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m  24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Transferred 308/349 items from weights/yolov5s.pt\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.0.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.0.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.0.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv3.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv3.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.cv3.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.m.0.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.m.0.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.m.0.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.m.0.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.m.0.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.2.m.0.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.3.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.3.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.3.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv3.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv3.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.cv3.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.0.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.0.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.0.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.0.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.0.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.0.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.1.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.1.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.1.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.1.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.1.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.4.m.1.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.5.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.5.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.5.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv3.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv3.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.cv3.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.0.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.0.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.0.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.0.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.0.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.0.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.1.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.1.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.1.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.1.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.1.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.1.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.2.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.2.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.2.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.2.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.2.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.6.m.2.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.7.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.7.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.7.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv3.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv3.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.cv3.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.m.0.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.m.0.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.m.0.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.m.0.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.m.0.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.8.m.0.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.9.cv1.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.9.cv1.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.9.cv1.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.9.cv2.conv.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.9.cv2.bn.weight\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m freezing model.9.cv2.bn.bias\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Scaled weight_decay = 0.0005\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/opt/ml/input/data/yolov5_input/train/labels' images and labels...765 found, 0 missing, 0 empty, 0 corrupted: 100% 765/765 [00:00<00:00, 3556.77it/s]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /opt/ml/input/data/yolov5_input/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/opt/ml/input/data/yolov5_input/valid/labels' images and labels...73 found, 0 missing, 0 empty, 0 corrupted: 100% 73/73 [00:00<00:00, 3709.70it/s]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mNew cache created: /opt/ml/input/data/yolov5_input/valid/labels.cache\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Image sizes 640 train, 640 val\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Using 0 dataloader workers\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Logging results to \u001b[1m/opt/ml/model/exp\u001b[0m\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Starting training for 1 epochs...\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m      Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/0      4.8G    0.1059    0.1414   0.04184      1479       640: 100% 12/12 [00:49<00:00,  4.11s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:10<00:00, 10.07s/it]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m                  all         73        967      0.361      0.122     0.0302    0.00703\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m 1 epochs completed in 0.017 hours.\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Validating /opt/ml/model/exp/weights/best.pt...\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Fusing layers... \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:12<00:00, 12.66s/it]\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m                  all         73        967       0.36      0.121     0.0302     0.0071\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m            Platelets         73         76          1          0          0          0\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m                  RBC         73        819     0.0813      0.363     0.0888     0.0205\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m                  WBC         73         72          0          0    0.00186   0.000766\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Waiting for W&B process to finish, PID 87... (success).\n",
      "wandb:                                                                                d)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Run history:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:        metrics/mAP_0.5 ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:   metrics/mAP_0.5:0.95 ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:      metrics/precision ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         metrics/recall ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         train/box_loss ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         train/cls_loss ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         train/obj_loss ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:           val/box_loss ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:           val/cls_loss ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:           val/obj_loss ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:                  x/lr0 ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:                  x/lr1 ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:                  x/lr2 ▁\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Run summary:\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:        metrics/mAP_0.5 0.03015\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:   metrics/mAP_0.5:0.95 0.00703\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:      metrics/precision 0.361\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         metrics/recall 0.12169\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         train/box_loss 0.10592\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         train/cls_loss 0.04184\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:         train/obj_loss 0.14135\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:           val/box_loss 0.09406\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:           val/cls_loss 0.0394\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:           val/obj_loss 0.11477\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:                  x/lr0 0.00011\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:                  x/lr1 0.00011\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb:                  x/lr2 0.09901\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Synced 5 W&B file(s), 45 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Synced yolov5-on-sagemaker-2021-11-08-12-23-24-937-algo-1-m9v5w: https://wandb.ai/annakie/model/runs/yolov5-on-sagemaker-2021-11-08-12-23-24-937-algo-1-m9v5w\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: Find logs at: ./wandb/run-20211108_122631-yolov5-on-sagemaker-2021-11-08-12-23-24-937-algo-1-m9v5w/logs/debug.log\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m wandb: \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m Results saved to \u001b[1m/opt/ml/model/exp\u001b[0m\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m \n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w |\u001b[0m 2021-11-08 12:28:12,137 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mn076r1dscw-algo-1-m9v5w exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator_local.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64ef74",
   "metadata": {},
   "source": [
    "## 9-1. SageMaker managed training\n",
    "축하합니다. 이제 SageMaker 환경에서 대용량 컴퓨팅 리소스를 활용하여 더 많은 Epoch를 수행하도록 하겠습니다. 이번에는 transfer learning을 하지 않고 from the scratch 방식으로 학습을 진행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b3c2a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8.1-gpu-py3'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:<tag>\n",
    "\n",
    "from sagemaker import image_uris\n",
    "image_uri = image_uris.retrieve(framework='pytorch',\n",
    "                                region='us-east-1',\n",
    "                                version='1.8.1',\n",
    "                                py_version='py3',\n",
    "                                image_scope='training', \n",
    "                                instance_type='ml.p3.2xlarge')\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "feaeab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b7e9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_managed = {\n",
    "    'data': 'data_sm.yaml',\n",
    "    'cfg': 'yolov5s.yaml',\n",
    "    'weights': 'weights/yolov5s.pt',\n",
    "    'batch-size': 128,\n",
    "    'epochs': 10,\n",
    "#     'epochs': 1,\n",
    "    'project': '/opt/ml/model',\n",
    "    'workers': 8,\n",
    "    'freeze': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5181947",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'yolov5-BCCD'\n",
    "instance_count = 1\n",
    "\n",
    "# instance_type = 'ml.p3.16xlarge'\n",
    "instance_type = 'ml.p2.8xlarge'\n",
    "# instance_type = 'ml.p3dn.24xlarge' \n",
    "# instance_type = 'ml.p4d.24xlarge'\n",
    "# instance_type = 'ml.m5.2xlarge'\n",
    "\n",
    "do_spot_training = True\n",
    "max_wait = 3*60*60\n",
    "max_run = 3*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be5dab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator_managed = PyTorch(\n",
    "    entry_point='train_sm.py',\n",
    "    source_dir=source_dir,\n",
    "    base_job_name='yolov5-on-sagemaker',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py36',\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    volume_size=256,\n",
    "#     code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters_managed,\n",
    "#     distribution=distribution,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_run=max_run,\n",
    "    checkpoint_s3_uri=checkpoint_s3_bucket,\n",
    "#     use_spot_instances=do_spot_training,  # spot instance 활용\n",
    "#     max_wait=max_wait, # spot instance 활용\n",
    "    profiler_config=profiler_config,\n",
    "    rules=rules,\n",
    "    disable_profiler=False # default: False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "321d8156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yolov5_input': 's3://sagemaker-us-east-1-889750940888/sinjoonk/yolov5'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {'yolov5_input': s3_data_path}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53fd4813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yolov5-BCCD-p2-1-dp-s-1109-05341636436051'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, hyperparameters_managed, instance_type, instance_count, do_spot_training)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62683b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: yolov5-on-sagemaker-2021-11-09-05-34-11-714\n"
     ]
    }
   ],
   "source": [
    "estimator_managed.fit(inputs=inputs,\n",
    "                      experiment_config={\n",
    "                          'TrialName': job_name,\n",
    "                          'TrialComponentDisplayName': job_name,\n",
    "                        },\n",
    "                      wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fe54d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=estimator_managed.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07a629e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-09 05:34:15 Starting - Starting the training job...\n",
      "2021-11-09 05:34:41 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      ".........\n",
      "2021-11-09 05:36:10 Starting - Preparing the instances for training............\n",
      "2021-11-09 05:38:02 Downloading - Downloading input data......\n",
      "2021-11-09 05:39:04 Training - Downloading the training image.....................\n",
      "2021-11-09 05:42:44 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-11-09 05:42:33,087 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-11-09 05:42:33,166 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-11-09 05:42:33,175 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-11-09 05:42:34,567 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mLooking in links: https://download.pytorch.org/whl/torch_stable.html\u001b[0m\n",
      "\u001b[34mCollecting torch==1.9.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp36-cp36m-linux_x86_64.whl (2041.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting torchvision==0.10.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp36-cp36m-linux_x86_64.whl (20.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting wandb\n",
      "  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 28)) (0.11.2)\u001b[0m\n",
      "\u001b[34mCollecting thop\u001b[0m\n",
      "\u001b[34m  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.9.1+cu111->-r requirements.txt (line 16)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.9.1+cu111->-r requirements.txt (line 16)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.10.1+cu111->-r requirements.txt (line 17)) (8.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision==0.10.1+cu111->-r requirements.txt (line 17)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (3.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.26.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.41.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 23)) (0.36.2)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.7-py3-none-any.whl (8.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (5.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting configparser>=3.8.1\n",
      "  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (2.8.2)\u001b[0m\n",
      "\u001b[34mCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.6/site-packages (from wandb->-r requirements.txt (line 24)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.6/site-packages (from seaborn>=0.11.0->-r requirements.txt (line 28)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.6/site-packages (from seaborn>=0.11.0->-r requirements.txt (line 28)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.6/site-packages (from seaborn>=0.11.0->-r requirements.txt (line 28)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from Click!=8.0.0,>=7.0->wandb->-r requirements.txt (line 24)) (4.8.1)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 23)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.0->-r requirements.txt (line 28)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.0->-r requirements.txt (line 28)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.0->-r requirements.txt (line 28)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23->seaborn>=0.11.0->-r requirements.txt (line 28)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 23)) (2.10)\u001b[0m\n",
      "\u001b[34mCollecting termcolor<2.0.0,>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 23)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb->-r requirements.txt (line 24)) (3.6.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: promise, subprocess32, pathtools, termcolor\n",
      "  Building wheel for promise (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=75ef809c7bdd3d7e7f63fa0d5c7ab994ccf5d0da790265312d256f4f2c60c9f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "  Building wheel for subprocess32 (setup.py): started\n",
      "  Building wheel for subprocess32 (setup.py): finished with status 'done'\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6488 sha256=aeaca1609ea739042974fa238a9e625f0f097673eca761e86e13d5883ec1386c\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/3a/ab/102386d84fe551b6cedb628ed1e74c5f5be76af8b909aeda09\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=5ac889228278086b2433f67f0fae593370f727c3db23f03866ecd1b02b502951\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/ea/90/e37d463fb3b03848bf715080595de62545266f53dd546b2497\n",
      "  Building wheel for termcolor (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=b3d1b9f741d7769a03adc3b7a7a5051d5ef80299e6988a7d7f1f08b0f02ebe6d\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\u001b[0m\n",
      "\u001b[34mSuccessfully built promise subprocess32 pathtools termcolor\u001b[0m\n",
      "\u001b[34mInstalling collected packages: smmap, pyasn1-modules, oauthlib, cachetools, termcolor, requests-oauthlib, google-auth, gitdb, yaspin, torch, tensorboard-plugin-wit, tensorboard-data-server, subprocess32, shortuuid, sentry-sdk, promise, pathtools, markdown, grpcio, google-auth-oauthlib, GitPython, docker-pycreds, configparser, absl-py, wandb, torchvision, thop, tensorboard\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\u001b[0m\n",
      "\u001b[34m    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.9.1\n",
      "    Uninstalling torchvision-0.9.1:\n",
      "      Successfully uninstalled torchvision-0.9.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed GitPython-3.1.18 absl-py-0.15.0 cachetools-4.2.4 configparser-5.1.0 docker-pycreds-0.4.0 gitdb-4.0.9 google-auth-2.3.3 google-auth-oauthlib-0.4.6 grpcio-1.41.1 markdown-3.3.4 oauthlib-3.1.1 pathtools-0.1.2 promise-2.3 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 sentry-sdk-1.4.3 shortuuid-1.0.7 smmap-5.0.0 subprocess32-3.5.4 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 termcolor-1.1.0 thop-0.0.31.post2005241907 torch-1.9.1+cu111 torchvision-0.10.1+cu111 wandb-0.12.6 yaspin-2.1.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-11-09 05:44:41,930 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"yolov5_input\": \"/opt/ml/input/data/yolov5_input\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"data\": \"data_sm.yaml\",\n",
      "        \"cfg\": \"yolov5s.yaml\",\n",
      "        \"project\": \"/opt/ml/model\",\n",
      "        \"weights\": \"weights/yolov5s.pt\",\n",
      "        \"batch-size\": 128,\n",
      "        \"freeze\": 10,\n",
      "        \"epochs\": 10,\n",
      "        \"workers\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"yolov5_input\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"yolov5-on-sagemaker-2021-11-09-05-34-11-714\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-889750940888/yolov5-on-sagemaker-2021-11-09-05-34-11-714/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sm.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"cfg\":\"yolov5s.yaml\",\"data\":\"data_sm.yaml\",\"epochs\":10,\"freeze\":10,\"project\":\"/opt/ml/model\",\"weights\":\"weights/yolov5s.pt\",\"workers\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_sm.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"yolov5_input\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"yolov5_input\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_sm\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-889750940888/yolov5-on-sagemaker-2021-11-09-05-34-11-714/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"yolov5_input\":\"/opt/ml/input/data/yolov5_input\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"cfg\":\"yolov5s.yaml\",\"data\":\"data_sm.yaml\",\"epochs\":10,\"freeze\":10,\"project\":\"/opt/ml/model\",\"weights\":\"weights/yolov5s.pt\",\"workers\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"yolov5_input\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"yolov5-on-sagemaker-2021-11-09-05-34-11-714\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-889750940888/yolov5-on-sagemaker-2021-11-09-05-34-11-714/source/sourcedir.tar.gz\",\"module_name\":\"train_sm\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sm.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--cfg\",\"yolov5s.yaml\",\"--data\",\"data_sm.yaml\",\"--epochs\",\"10\",\"--freeze\",\"10\",\"--project\",\"/opt/ml/model\",\"--weights\",\"weights/yolov5s.pt\",\"--workers\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_YOLOV5_INPUT=/opt/ml/input/data/yolov5_input\u001b[0m\n",
      "\u001b[34mSM_HP_DATA=data_sm.yaml\u001b[0m\n",
      "\u001b[34mSM_HP_CFG=yolov5s.yaml\u001b[0m\n",
      "\u001b[34mSM_HP_PROJECT=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHTS=weights/yolov5s.pt\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_FREEZE=10\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_WORKERS=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_sm.py --batch-size 128 --cfg yolov5s.yaml --data data_sm.yaml --epochs 10 --freeze 10 --project /opt/ml/model --weights weights/yolov5s.pt --workers 8\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mTHIS IS train_sm.py!!!\u001b[0m\n",
      "\u001b[34mtorchvision version: 0.10.1+cu111\u001b[0m\n",
      "\u001b[34mtorch version: 1.9.1+cu111\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mgithub: #033[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\u001b[0m\n",
      "\u001b[34mParse error at \"'--find-l'\": Expected W:(abcd...)\u001b[0m\n",
      "\u001b[34mPlotting labels... #015\u001b[0m\n",
      "\u001b[34m#015\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mautoanchor: #033[0mAnalyzing anchors... anchors/target = 5.30, Best Possible Recall (BPR) = 0.9994#015\u001b[0m\n",
      "\u001b[34m#015\u001b[0m\n",
      "\u001b[34malgo-1:61:622 [0] ofi_init:1136 NCCL WARN NET/OFI Only EFA provider is supported#015\u001b[0m\n",
      "\u001b[34mNCCL version 2.7.8+cuda11.1#015\u001b[0m\n",
      "\u001b[34mOptimizer stripped from /opt/ml/model/exp/weights/last.pt, 14.5MB#015\u001b[0m\n",
      "\u001b[34mOptimizer stripped from /opt/ml/model/exp/weights/best.pt, 14.5MB#015\u001b[0m\n",
      "LowGPUUtilization: IssuesFound\n",
      "ProfilerReport: InProgress\n",
      "\u001b[34mwandb: Currently logged in as: annakie (use `wandb login --relogin` to force relogin)\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mtrain_sm: #033[0mweights=weights/yolov5s.pt, cfg=yolov5s.yaml, data=data_sm.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=128, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=/opt/ml/model, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=10, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34mYOLOv5 🚀 2021-11-8 torch 1.9.1+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
      "\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mhyperparameters: #033[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mTensorBoard: #033[0mStart with 'tensorboard --logdir /opt/ml/model', view at http://localhost:6006/\u001b[0m\n",
      "\u001b[34mwandb: Tracking run with wandb version 0.12.6\u001b[0m\n",
      "\u001b[34mwandb: Syncing run yolov5-on-sagemaker-2021-11-09-05-34-11-714-algo-1\u001b[0m\n",
      "\u001b[34mwandb: ⭐️ View project at https://wandb.ai/annakie/model\u001b[0m\n",
      "\u001b[34mwandb: 🚀 View run at https://wandb.ai/annakie/model/runs/yolov5-on-sagemaker-2021-11-09-05-34-11-714-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Run data is saved locally in /opt/ml/code/wandb/run-20211109_054451-yolov5-on-sagemaker-2021-11-09-05-34-11-714-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[34mOverriding model.yaml nc=80 with nc=3#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "                 from  n    params  module                                  arguments                     #015\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              #015\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                #015\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   #015\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               #015\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 #015\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              #015\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 #015\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              #015\u001b[0m\n",
      "\u001b[34m2021-11-09 05:48:56,190 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 #015\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 #015\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              #015\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          #015\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           #015\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          #015\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              #015\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          #015\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           #015\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          #015\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              #015\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           #015\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          #015\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              #015\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           #015\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          #015\n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]#015\u001b[0m\n",
      "\u001b[34mModel Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs#015\u001b[0m\n",
      "\u001b[34m#015\u001b[0m\n",
      "\u001b[34mTransferred 308/349 items from weights/yolov5s.pt#015\u001b[0m\n",
      "\u001b[34mfreezing model.0.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.0.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.0.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv3.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv3.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.cv3.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.m.0.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.m.0.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.m.0.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.m.0.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.m.0.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.2.m.0.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.3.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.3.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.3.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv3.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv3.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.cv3.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.0.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.0.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.0.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.0.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.0.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.0.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.1.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.1.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.1.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.1.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.1.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.4.m.1.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.5.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.5.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.5.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv3.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv3.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.cv3.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.0.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.0.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.0.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.0.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.0.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.0.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.1.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.1.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.1.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.1.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.1.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.1.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.2.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.2.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.2.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.2.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.2.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.6.m.2.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.7.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.7.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.7.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv3.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv3.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.cv3.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.m.0.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.m.0.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.m.0.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.m.0.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.m.0.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.8.m.0.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.9.cv1.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.9.cv1.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.9.cv1.bn.bias#015\u001b[0m\n",
      "\u001b[34mfreezing model.9.cv2.conv.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.9.cv2.bn.weight#015\u001b[0m\n",
      "\u001b[34mfreezing model.9.cv2.bn.bias#015\u001b[0m\n",
      "\u001b[34mScaled weight_decay = 0.001#015\u001b[0m\n",
      "\u001b[34m#033[34m#033[1moptimizer:#033[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias#015\u001b[0m\n",
      "\u001b[34mDP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.#015\u001b[0m\n",
      "\u001b[34mSee Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.#015\u001b[0m\n",
      "\u001b[34m#015#033[34m#033[1mtrain: #033[0mScanning '/opt/ml/input/data/yolov5_input/train/labels.cache' images and labels... 765 found, 0 missing, 0 empty, 0 corrupted: 100% 765/765 [00:00<?, ?it/s]#015#033[34m#033[1mtrain: #033[0mScanning '/opt/ml/input/data/yolov5_input/train/labels.cache' images and labels... 765 found, 0 missing, 0 empty, 0 corrupted: 100% 765/765 [00:00<?, ?it/s]#015\u001b[0m\n",
      "\u001b[34m#015#033[34m#033[1mval: #033[0mScanning '/opt/ml/input/data/yolov5_input/valid/labels.cache' images and labels... 73 found, 0 missing, 0 empty, 0 corrupted: 100% 73/73 [00:00<?, ?it/s]#015#033[34m#033[1mval: #033[0mScanning '/opt/ml/input/data/yolov5_input/valid/labels.cache' images and labels... 73 found, 0 missing, 0 empty, 0 corrupted: 100% 73/73 [00:00<?, ?it/s]#015\u001b[0m\n",
      "\u001b[34mImage sizes 640 train, 640 val#015\u001b[0m\n",
      "\u001b[34mUsing 8 dataloader workers#015\u001b[0m\n",
      "\u001b[34mLogging results to #033[1m/opt/ml/model/exp#033[0m#015\u001b[0m\n",
      "\u001b[34mStarting training for 10 epochs...#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       0/9     1.67G     0.113    0.1427   0.04443      3052       640:   0% 0/6 [00:18<?, ?it/s]#015       0/9     1.67G     0.113    0.1427   0.04443      3052       640:  17% 1/6 [00:20<01:44, 20.83s/it]#015       0/9     2.95G    0.1119     0.128   0.04408      2266       640:  17% 1/6 [00:23<01:44, 20.83s/it]#015       0/9     2.95G    0.1119     0.128   0.04408      2266       640:  33% 2/6 [00:23<00:39,  9.91s/it]#015       0/9     3.58G    0.1106    0.1272   0.04371      2456       640:  33% 2/6 [00:26<00:39,  9.91s/it]#015       0/9     3.58G    0.1106    0.1272   0.04371      2456       640:  50% 3/6 [00:26<00:21,  7.09s/it]#015       0/9     3.58G    0.1093    0.1291   0.04338      2525       640:  50% 3/6 [00:28<00:21,  7.09s/it]#015       0/9     3.58G    0.1093    0.1291   0.04338      2525       640:  67% 4/6 [00:28<00:10,  5.05s/it]#015       0/9     3.58G    0.1078    0.1334   0.04291      2678       640:  67% 4/6 [00:29<00:10,  5.05s/it]#015       0/9     3.58G    0.1078    0.1334   0.04291      2678       640:  83% 5/6 [00:29<00:03,  3.68s/it]#015       0/9     3.58G    0.1064    0.1397   0.04233      2984       640:  83% 5/6 [00:30<00:03,  3.68s/it]#015       0/9     3.58G    0.1064    0.1397   0.04233      2984       640: 100% 6/6 [00:30<00:00,  2.65s/it]#015       0/9     3.58G    0.1064    0.1397   0.04233      2984       640: 100% 6/6 [00:30<00:00,  5.11s/it]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.72s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.72s/it]#015\n",
      "                 all         73        967      0.692      0.154     0.0269    0.00652#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       1/9     3.58G   0.09671    0.1533   0.03829      2671       640:   0% 0/6 [00:00<?, ?it/s]#015       1/9     3.58G   0.09671    0.1533   0.03829      2671       640:  17% 1/6 [00:00<00:03,  1.53it/s]#015       1/9     3.58G   0.09626    0.1509   0.03749      2502       640:  17% 1/6 [00:01<00:03,  1.53it/s]#015       1/9     3.58G   0.09626    0.1509   0.03749      2502       640:  33% 2/6 [00:01<00:02,  1.55it/s]#015       1/9     3.58G   0.09544     0.148   0.03695      2340       640:  33% 2/6 [00:01<00:02,  1.55it/s]#015       1/9     3.58G   0.09544     0.148   0.03695      2340       640:  50% 3/6 [00:01<00:01,  1.56it/s]#015       1/9     3.58G   0.09487    0.1463   0.03643      2280       640:  50% 3/6 [00:02<00:01,  1.56it/s]#015       1/9     3.58G   0.09487    0.1463   0.03643      2280       640:  67% 4/6 [00:02<00:01,  1.55it/s]#015       1/9     3.58G   0.09437    0.1462   0.03592      2359       640:  67% 4/6 [00:03<00:01,  1.55it/s]#015       1/9     3.58G   0.09437    0.1462   0.03592      2359       640:  83% 5/6 [00:03<00:00,  1.43it/s]#015       1/9     3.58G   0.09389    0.1487   0.03527      2588       640:  83% 5/6 [00:04<00:00,  1.43it/s]#015       1/9     3.58G   0.09389    0.1487   0.03527      2588       640: 100% 6/6 [00:04<00:00,  1.47it/s]#015       1/9     3.58G   0.09389    0.1487   0.03527      2588       640: 100% 6/6 [00:04<00:00,  1.49it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.99s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.99s/it]#015\n",
      "                 all         73        967     0.0344      0.116     0.0338    0.00692#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       2/9     3.58G   0.09052    0.1856   0.03091      3033       640:   0% 0/6 [00:00<?, ?it/s]#015       2/9     3.58G   0.09052    0.1856   0.03091      3033       640:  17% 1/6 [00:00<00:03,  1.57it/s]#015       2/9     3.58G   0.09018    0.1706    0.0305      2493       640:  17% 1/6 [00:01<00:03,  1.57it/s]#015       2/9     3.58G   0.09018    0.1706    0.0305      2493       640:  33% 2/6 [00:01<00:02,  1.55it/s]#015       2/9     3.58G    0.0901    0.1663   0.03015      2514       640:  33% 2/6 [00:01<00:02,  1.55it/s]#015       2/9     3.58G    0.0901    0.1663   0.03015      2514       640:  50% 3/6 [00:01<00:01,  1.55it/s]#015       2/9     3.58G   0.08976    0.1644   0.02972      2520       640:  50% 3/6 [00:02<00:01,  1.55it/s]#015       2/9     3.58G   0.08976    0.1644   0.02972      2520       640:  67% 4/6 [00:02<00:01,  1.55it/s]#015       2/9     3.58G    0.0894    0.1648   0.02924      2666       640:  67% 4/6 [00:03<00:01,  1.55it/s]#015       2/9     3.58G    0.0894    0.1648   0.02924      2666       640:  83% 5/6 [00:03<00:00,  1.47it/s]#015       2/9     3.58G   0.08888    0.1651   0.02874      2603       640:  83% 5/6 [00:03<00:00,  1.47it/s]#015       2/9     3.58G   0.08888    0.1651   0.02874      2603       640: 100% 6/6 [00:03<00:00,  1.50it/s]#015       2/9     3.58G   0.08888    0.1651   0.02874      2603       640: 100% 6/6 [00:03<00:00,  1.51it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:14<00:00, 14.40s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:14<00:00, 14.40s/it]#015\n",
      "                 all         73        967     0.0271     0.0895     0.0214    0.00437#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       3/9     3.58G   0.08654    0.1792   0.02564      2900       640:   0% 0/6 [00:00<?, ?it/s]#015       3/9     3.58G   0.08654    0.1792   0.02564      2900       640:  17% 1/6 [00:00<00:03,  1.54it/s]#015       3/9     3.58G   0.08639    0.1729   0.02542      2628       640:  17% 1/6 [00:01<00:03,  1.54it/s]#015       3/9     3.58G   0.08639    0.1729   0.02542      2628       640:  33% 2/6 [00:01<00:02,  1.54it/s]#015       3/9     3.58G   0.08596     0.171   0.02506      2633       640:  33% 2/6 [00:01<00:02,  1.54it/s]#015       3/9     3.58G   0.08596     0.171   0.02506      2633       640:  50% 3/6 [00:01<00:01,  1.54it/s]#015       3/9     3.58G   0.08567    0.1676   0.02481      2472       640:  50% 3/6 [00:02<00:01,  1.54it/s]#015       3/9     3.58G   0.08567    0.1676   0.02481      2472       640:  67% 4/6 [00:02<00:01,  1.48it/s]#015       3/9     3.58G   0.08532    0.1659   0.02443      2524       640:  67% 4/6 [00:03<00:01,  1.48it/s]#015       3/9     3.58G   0.08532    0.1659   0.02443      2524       640:  83% 5/6 [00:03<00:00,  1.50it/s]#015       3/9     3.58G   0.08499    0.1661   0.02408      2639       640:  83% 5/6 [00:03<00:00,  1.50it/s]#015       3/9     3.58G   0.08499    0.1661   0.02408      2639       640: 100% 6/6 [00:03<00:00,  1.52it/s]#015       3/9     3.58G   0.08499    0.1661   0.02408      2639       640: 100% 6/6 [00:03<00:00,  1.52it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:14<00:00, 14.85s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:14<00:00, 14.85s/it]#015\n",
      "                 all         73        967     0.0241     0.0452     0.0117    0.00227#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       4/9     3.58G    0.0845    0.1857   0.02245      3034       640:   0% 0/6 [00:00<?, ?it/s]#015       4/9     3.58G    0.0845    0.1857   0.02245      3034       640:  17% 1/6 [00:00<00:03,  1.52it/s]#015       4/9     3.58G   0.08396    0.1704   0.02265      2484       640:  17% 1/6 [00:01<00:03,  1.52it/s]#015       4/9     3.58G   0.08396    0.1704   0.02265      2484       640:  33% 2/6 [00:01<00:02,  1.54it/s]#015       4/9     3.58G   0.08327    0.1654   0.02233      2437       640:  33% 2/6 [00:02<00:02,  1.54it/s]#015       4/9     3.58G   0.08327    0.1654   0.02233      2437       640:  50% 3/6 [00:02<00:02,  1.45it/s]#015       4/9     3.58G   0.08311    0.1654    0.0221      2647       640:  50% 3/6 [00:02<00:02,  1.45it/s]#015       4/9     3.58G   0.08311    0.1654    0.0221      2647       640:  67% 4/6 [00:02<00:01,  1.49it/s]#015       4/9     3.58G   0.08295    0.1653   0.02184      2661       640:  67% 4/6 [00:03<00:01,  1.49it/s]#015       4/9     3.58G   0.08295    0.1653   0.02184      2661       640:  83% 5/6 [00:03<00:00,  1.51it/s]#015       4/9     3.58G   0.08253    0.1658   0.02157      2654       640:  83% 5/6 [00:03<00:00,  1.51it/s]#015       4/9     3.58G   0.08253    0.1658   0.02157      2654       640: 100% 6/6 [00:03<00:00,  1.51it/s]#015       4/9     3.58G   0.08253    0.1658   0.02157      2654       640: 100% 6/6 [00:03<00:00,  1.51it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:17<00:00, 17.20s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:17<00:00, 17.20s/it]#015\n",
      "                 all         73        967      0.345     0.0419    0.00866    0.00139#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       5/9     3.58G    0.0816    0.1877   0.02032      3071       640:   0% 0/6 [00:00<?, ?it/s]#015       5/9     3.58G    0.0816    0.1877   0.02032      3071       640:  17% 1/6 [00:00<00:03,  1.53it/s]#015       5/9     3.58G   0.08085    0.1746   0.02007      2618       640:  17% 1/6 [00:01<00:03,  1.53it/s]#015       5/9     3.58G   0.08085    0.1746   0.02007      2618       640:  33% 2/6 [00:01<00:02,  1.47it/s]#015       5/9     3.58G   0.08049    0.1711   0.02001      2656       640:  33% 2/6 [00:02<00:02,  1.47it/s]#015       5/9     3.58G   0.08049    0.1711   0.02001      2656       640:  50% 3/6 [00:02<00:02,  1.49it/s]#015       5/9     3.58G   0.07997    0.1674   0.02004      2480       640:  50% 3/6 [00:02<00:02,  1.49it/s]#015       5/9     3.58G   0.07997    0.1674   0.02004      2480       640:  67% 4/6 [00:02<00:01,  1.50it/s]#015       5/9     3.58G   0.07958    0.1648   0.02001      2429       640:  67% 4/6 [00:03<00:01,  1.50it/s]#015       5/9     3.58G   0.07958    0.1648   0.02001      2429       640:  83% 5/6 [00:03<00:00,  1.52it/s]#015       5/9     3.58G   0.07932     0.164    0.0199      2521       640:  83% 5/6 [00:03<00:00,  1.52it/s]#015       5/9     3.58G   0.07932     0.164    0.0199      2521       640: 100% 6/6 [00:03<00:00,  1.52it/s]#015       5/9     3.58G   0.07932     0.164    0.0199      2521       640: 100% 6/6 [00:03<00:00,  1.51it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:17<00:00, 17.24s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:17<00:00, 17.24s/it]#015\n",
      "                 all         73        967      0.682     0.0529    0.00948     0.0017#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       6/9     3.58G    0.0784    0.1763   0.01933      2875       640:   0% 0/6 [00:00<?, ?it/s]#015       6/9     3.58G    0.0784    0.1763   0.01933      2875       640:  17% 1/6 [00:00<00:03,  1.56it/s]#015       6/9     3.58G    0.0783    0.1707   0.01935      2658       640:  17% 1/6 [00:01<00:03,  1.56it/s]#015       6/9     3.58G    0.0783    0.1707   0.01935      2658       640:  33% 2/6 [00:01<00:02,  1.54it/s]#015       6/9     3.58G    0.0777    0.1665   0.01904      2524       640:  33% 2/6 [00:01<00:02,  1.54it/s]#015       6/9     3.58G    0.0777    0.1665   0.01904      2524       640:  50% 3/6 [00:01<00:01,  1.54it/s]#015       6/9     3.58G   0.07753     0.165   0.01875      2582       640:  50% 3/6 [00:02<00:01,  1.54it/s]#015       6/9     3.58G   0.07753     0.165   0.01875      2582       640:  67% 4/6 [00:02<00:01,  1.54it/s]#015       6/9     3.58G   0.07715    0.1638   0.01855      2581       640:  67% 4/6 [00:03<00:01,  1.54it/s]#015       6/9     3.58G   0.07715    0.1638   0.01855      2581       640:  83% 5/6 [00:03<00:00,  1.53it/s]#015       6/9     3.58G   0.07677    0.1633   0.01833      2560       640:  83% 5/6 [00:03<00:00,  1.53it/s]#015       6/9     3.58G   0.07677    0.1633   0.01833      2560       640: 100% 6/6 [00:03<00:00,  1.53it/s]#015       6/9     3.58G   0.07677    0.1633   0.01833      2560       640: 100% 6/6 [00:03<00:00,  1.54it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:14<00:00, 14.46s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:14<00:00, 14.46s/it]#015\n",
      "                 all         73        967       0.69     0.0667     0.0168    0.00331#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       7/9     3.58G   0.07711    0.1915    0.0177      3163       640:   0% 0/6 [00:00<?, ?it/s]#015       7/9     3.58G   0.07711    0.1915    0.0177      3163       640:  17% 1/6 [00:00<00:03,  1.55it/s]#015       7/9     3.58G   0.07659    0.1777   0.01801      2696       640:  17% 1/6 [00:01<00:03,  1.55it/s]#015       7/9     3.58G   0.07659    0.1777   0.01801      2696       640:  33% 2/6 [00:01<00:02,  1.53it/s]#015       7/9     3.58G   0.07601    0.1716   0.01809      2585       640:  33% 2/6 [00:01<00:02,  1.53it/s]#015       7/9     3.58G   0.07601    0.1716   0.01809      2585       640:  50% 3/6 [00:01<00:01,  1.53it/s]#015       7/9     3.58G   0.07571    0.1681   0.01792      2519       640:  50% 3/6 [00:02<00:01,  1.53it/s]#015       7/9     3.58G   0.07571    0.1681   0.01792      2519       640:  67% 4/6 [00:02<00:01,  1.53it/s]#015       7/9     3.58G    0.0756    0.1669   0.01797      2593       640:  67% 4/6 [00:03<00:01,  1.53it/s]#015       7/9     3.58G    0.0756    0.1669   0.01797      2593       640:  83% 5/6 [00:03<00:00,  1.52it/s]#015       7/9     3.58G   0.07498    0.1645   0.01784      2416       640:  83% 5/6 [00:04<00:00,  1.52it/s]#015       7/9     3.58G   0.07498    0.1645   0.01784      2416       640: 100% 6/6 [00:04<00:00,  1.46it/s]#015       7/9     3.58G   0.07498    0.1645   0.01784      2416       640: 100% 6/6 [00:04<00:00,  1.50it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:10<00:00, 10.31s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:10<00:00, 10.31s/it]#015\n",
      "                 all         73        967      0.695      0.037     0.0146    0.00282#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       8/9     3.58G    0.0751     0.177   0.01805      2901       640:   0% 0/6 [00:00<?, ?it/s]#015       8/9     3.58G    0.0751     0.177   0.01805      2901       640:  17% 1/6 [00:00<00:03,  1.54it/s]#015       8/9     3.58G   0.07451    0.1694   0.01764      2579       640:  17% 1/6 [00:01<00:03,  1.54it/s]#015       8/9     3.58G   0.07451    0.1694   0.01764      2579       640:  33% 2/6 [00:01<00:02,  1.54it/s]#015       8/9     3.58G   0.07394    0.1665   0.01759      2572       640:  33% 2/6 [00:01<00:02,  1.54it/s]#015       8/9     3.58G   0.07394    0.1665   0.01759      2572       640:  50% 3/6 [00:01<00:01,  1.53it/s]#015       8/9     3.58G   0.07363    0.1644   0.01755      2530       640:  50% 3/6 [00:02<00:01,  1.53it/s]#015       8/9     3.58G   0.07363    0.1644   0.01755      2530       640:  67% 4/6 [00:02<00:01,  1.53it/s]#015       8/9     3.58G   0.07347    0.1612   0.01765      2387       640:  67% 4/6 [00:03<00:01,  1.53it/s]#015       8/9     3.58G   0.07347    0.1612   0.01765      2387       640:  83% 5/6 [00:03<00:00,  1.46it/s]#015       8/9     3.58G   0.07298    0.1611   0.01735      2580       640:  83% 5/6 [00:04<00:00,  1.46it/s]#015       8/9     3.58G   0.07298    0.1611   0.01735      2580       640: 100% 6/6 [00:04<00:00,  1.48it/s]#015       8/9     3.58G   0.07298    0.1611   0.01735      2580       640: 100% 6/6 [00:04<00:00,  1.50it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.79s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.79s/it]#015\n",
      "                 all         73        967     0.0125      0.105     0.0105    0.00201#015\u001b[0m\n",
      "\u001b[34m#015\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size#015\u001b[0m\n",
      "\u001b[34m#015  0% 0/6 [00:00<?, ?it/s]#015       9/9     3.58G   0.07348    0.1773   0.01742      2882       640:   0% 0/6 [00:00<?, ?it/s]#015       9/9     3.58G   0.07348    0.1773   0.01742      2882       640:  17% 1/6 [00:00<00:03,  1.54it/s]#015       9/9     3.58G    0.0726    0.1703   0.01789      2666       640:  17% 1/6 [00:01<00:03,  1.54it/s]#015       9/9     3.58G    0.0726    0.1703   0.01789      2666       640:  33% 2/6 [00:01<00:02,  1.53it/s]#015       9/9     3.58G   0.07228    0.1677   0.01751      2603       640:  33% 2/6 [00:01<00:02,  1.53it/s]#015       9/9     3.58G   0.07228    0.1677   0.01751      2603       640:  50% 3/6 [00:01<00:01,  1.54it/s]#015       9/9     3.58G   0.07197    0.1639   0.01765      2437       640:  50% 3/6 [00:02<00:01,  1.54it/s]#015       9/9     3.58G   0.07197    0.1639   0.01765      2437       640:  67% 4/6 [00:02<00:01,  1.47it/s]#015       9/9     3.58G   0.07175     0.164   0.01758      2635       640:  67% 4/6 [00:03<00:01,  1.47it/s]#015       9/9     3.58G   0.07175     0.164   0.01758      2635       640:  83% 5/6 [00:03<00:00,  1.49it/s]#015       9/9     3.58G   0.07159     0.164   0.01735      2648       640:  83% 5/6 [00:03<00:00,  1.49it/s]#015       9/9     3.58G   0.07159     0.164   0.01735      2648       640: 100% 6/6 [00:03<00:00,  1.50it/s]#015       9/9     3.58G   0.07159     0.164   0.01735      2648       640: 100% 6/6 [00:03<00:00,  1.50it/s]#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.65s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:09<00:00,  9.65s/it]#015\n",
      "                 all         73        967      0.018      0.133     0.0116    0.00238#015\u001b[0m\n",
      "\u001b[34m#015\u001b[0m\n",
      "\u001b[34m10 epochs completed in 0.056 hours.#015\u001b[0m\n",
      "\u001b[34m#015\u001b[0m\n",
      "\u001b[34mValidating /opt/ml/model/exp/weights/best.pt...#015\u001b[0m\n",
      "\u001b[34mFusing layers... #015\u001b[0m\n",
      "\u001b[34mModel Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs#015\u001b[0m\n",
      "\u001b[34m#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0% 0/1 [00:00<?, ?it/s]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:11<00:00, 11.51s/it]#015               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:11<00:00, 11.51s/it]#015\n",
      "                 all         73        967     0.0344      0.116     0.0338    0.00698#015\n",
      "           Platelets         73         76          0          0          0          0#015\n",
      "                 RBC         73        819      0.103      0.349      0.101     0.0209#015\n",
      "                 WBC         73         72          0          0          0          0#015\u001b[0m\n",
      "\u001b[34mwandb: Waiting for W&B process to finish, PID 141... (success).\u001b[0m\n",
      "\u001b[34mwandb: - 82.48MB of 82.48MB uploaded (0.00MB deduped)#015wandb: \\ 82.48MB of 82.48MB uploaded (0.00MB deduped)#015wandb: | 82.48MB of 82.48MB uploaded (0.00MB deduped)#015wandb: / 82.48MB of 82.50MB uploaded (0.00MB deduped)#015wandb: - 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb: \\ 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb: | 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb: / 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb: - 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb: \\ 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb: | 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb: / 82.50MB of 82.50MB uploaded (0.00MB deduped)#015wandb:                                                                                \u001b[0m\n",
      "\u001b[34mwandb: Run history:\u001b[0m\n",
      "\u001b[34mwandb:        metrics/mAP_0.5 ▆█▅▂▁▁▃▃▂▂\u001b[0m\n",
      "\u001b[34mwandb:   metrics/mAP_0.5:0.95 ██▅▂▁▁▃▃▂▂\u001b[0m\n",
      "\u001b[34mwandb:      metrics/precision █▁▁▁▄███▁▁\u001b[0m\n",
      "\u001b[34mwandb:         metrics/recall █▆▄▁▁▂▃▁▅▇\u001b[0m\n",
      "\u001b[34mwandb:         train/box_loss █▅▄▄▃▃▂▂▁▁\u001b[0m\n",
      "\u001b[34mwandb:         train/cls_loss █▆▄▃▂▂▁▁▁▁\u001b[0m\n",
      "\u001b[34mwandb:         train/obj_loss ▁▃███▇▇█▇▇\u001b[0m\n",
      "\u001b[34mwandb:           val/box_loss █▃▁▁▁▂▃▃▄▄\u001b[0m\n",
      "\u001b[34mwandb:           val/cls_loss █▅▂▁▂▃▂▁▃▃\u001b[0m\n",
      "\u001b[34mwandb:           val/obj_loss ▁▅▆▇██▅▄▃▂\u001b[0m\n",
      "\u001b[34mwandb:                  x/lr0 ▁▄▆▇██▇▅▃▂\u001b[0m\n",
      "\u001b[34mwandb:                  x/lr1 ▁▄▆▇██▇▅▃▂\u001b[0m\n",
      "\u001b[34mwandb:                  x/lr2 █▇▇▆▅▄▃▃▂▁\u001b[0m\n",
      "\u001b[34mwandb: \u001b[0m\n",
      "\u001b[34mwandb: Run summary:\u001b[0m\n",
      "\u001b[34mwandb:        metrics/mAP_0.5 0.01161\u001b[0m\n",
      "\u001b[34mwandb:   metrics/mAP_0.5:0.95 0.00238\u001b[0m\n",
      "\u001b[34mwandb:      metrics/precision 0.01798\u001b[0m\n",
      "\u001b[34mwandb:         metrics/recall 0.13258\u001b[0m\n",
      "\u001b[34mwandb:         train/box_loss 0.07159\u001b[0m\n",
      "\u001b[34mwandb:         train/cls_loss 0.01735\u001b[0m\n",
      "\u001b[34mwandb:         train/obj_loss 0.16404\u001b[0m\n",
      "\u001b[34mwandb:           val/box_loss 0.0856\u001b[0m\n",
      "\u001b[34mwandb:           val/cls_loss 0.0348\u001b[0m\n",
      "\u001b[34mwandb:           val/obj_loss 0.11914\u001b[0m\n",
      "\u001b[34mwandb:                  x/lr0 7e-05\u001b[0m\n",
      "\u001b[34mwandb:                  x/lr1 7e-05\u001b[0m\n",
      "\u001b[34mwandb:                  x/lr2 0.09417\u001b[0m\n",
      "\u001b[34mwandb: \u001b[0m\n",
      "\u001b[34mwandb: Synced 5 W&B file(s), 333 media file(s), 1 artifact file(s) and 0 other file(s)\u001b[0m\n",
      "\u001b[34mwandb: Synced yolov5-on-sagemaker-2021-11-09-05-34-11-714-algo-1: https://wandb.ai/annakie/model/runs/yolov5-on-sagemaker-2021-11-09-05-34-11-714-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Find logs at: ./wandb/run-20211109_054451-yolov5-on-sagemaker-2021-11-09-05-34-11-714-algo-1/logs/debug.log\u001b[0m\n",
      "\u001b[34mwandb: \u001b[0m\n",
      "\u001b[34mResults saved to #033[1m/opt/ml/model/exp#033[0m\n",
      "\u001b[0m\n",
      "\n",
      "2021-11-09 05:49:24 Uploading - Uploading generated training model\n",
      "2021-11-09 05:49:24 Completed - Training job completed\n",
      "LossNotDecreasing: Error\n",
      "Training seconds: 672\n",
      "Billable seconds: 672\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f237c9a",
   "metadata": {},
   "source": [
    "## 10. 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2dc9960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-889750940888/sinjoonk/yolov5/output/yolov5-on-sagemaker-2021-11-08-12-31-03-296/output/\n",
      "2021-11-08 12:55:47   29.5 MiB model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifacts_dir = estimator_managed.model_data.replace('model.tar.gz', '')\n",
    "print(artifacts_dir)\n",
    "!aws s3 ls --human-readable {artifacts_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc2cf2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-889750940888/sinjoonk/yolov5/output/yolov5-on-sagemaker-2021-11-08-12-31-03-296/output/model.tar.gz to model/model.tar.gz\n",
      "exp/\n",
      "exp/results.csv\n",
      "exp/results.png\n",
      "exp/R_curve.png\n",
      "exp/train_batch0.jpg\n",
      "exp/PR_curve.png\n",
      "exp/labels_correlogram.jpg\n",
      "exp/train_batch1.jpg\n",
      "exp/confusion_matrix.png\n",
      "exp/val_batch0_pred.jpg\n",
      "exp/labels.jpg\n",
      "exp/events.out.tfevents.1636375290.algo-1.61.0\n",
      "exp/F1_curve.png\n",
      "exp/val_batch0_labels.jpg\n",
      "exp/weights/\n",
      "exp/weights/best.pt\n",
      "exp/weights/last.pt\n",
      "exp/P_curve.png\n",
      "exp/train_batch2.jpg\n",
      "exp/hyp.yaml\n",
      "exp/opt.yaml\n"
     ]
    }
   ],
   "source": [
    "model_dir = './model'\n",
    "\n",
    "!rm -rf $model_dir\n",
    "\n",
    "import json , os\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "!aws s3 cp {artifacts_dir}model.tar.gz {model_dir}/model.tar.gz\n",
    "!tar -xvzf {model_dir}/model.tar.gz -C {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5025c",
   "metadata": {},
   "source": [
    "SageMaker **Studio** notebook에 접속한 후 **Experiments and Trial**에서 Trial component별 세부 정보를 확인할 수도 있습니다.\n",
    "\n",
    "<p align=\"center\">\n",
    "<center><img src=\"./image/sm-experiments-details.png\" height=\"400\" width=\"800\" alt=\"\"><center>\n",
    "<br><br>\n",
    "<b>Figure 2.SageMaker Experiments 세부 내역</b> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eae223",
   "metadata": {},
   "source": [
    "# Optional: BYOC\n",
    "만약 SageMaker prebuild docker container image가 여러분들의 usecase에 맞지 않다면 직접 container image를 만들고 SageMaker 환경에서 학습/추론에 활용할 수 있습니다.\n",
    "\n",
    "> Sagemaker training toolkit:\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-training-container.html  \n",
    "> Custom SDK framework estimator: https://github.com/giuseppeporcelli/sagemaker-custom-training-containers/blob/master/script-mode-container-2/notebook/script-mode-container-2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402249a",
   "metadata": {},
   "source": [
    "## Container image build and push\n",
    "YOLOv5의 공식 Dockerfile에 SageMaker training toolkit을 설치하고 학습코드가 저장될 `/opt/ml/code`를 만듭니다. \n",
    "```\n",
    "#Dockerfile\n",
    "...\n",
    "# Install sagemaker-training toolkit that contains the common functionality necessary to create a container compatible with SageMaker and the Python SDK.\n",
    "RUN pip3 install sagemaker-training\n",
    "\n",
    "RUN mkdir -p /opt/ml/code\n",
    "WORKDIR /opt/ml/code\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97bfea",
   "metadata": {},
   "source": [
    "`build_and_push.sh` [YOUR_ECR_REPOSITORY_NAMAE] 명령을 수행하여 Container이미지를 만들어 ECR에 Push합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5-sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "!sh + build_and_push.sh sinjoonk-yolov5\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61123381",
   "metadata": {},
   "source": [
    "## Local mode training\n",
    "`Framework` class를 상속하여 `CustomFramework` class를 정의합니다. `Framework` class는 `sagemaker.tensorflow.estimator.TensorFlow`, `sagemaker.tensorflow.estimator.PyTorch`, `sagemaker.sklearn.estimator.SKLearn`의 부모 class입니다.\n",
    "\n",
    "**References**\n",
    "> Amazon SageMaker SDK 2.x 사용법 (5가지 핵심 오브젝트) – 강성문:: AWS Innovate 2021\n",
    ": https://www.youtube.com/watch?v=n2Ky1nZXyWo&ab_channel=AmazonWebServicesKorea  \n",
    "> sagemaker.estimator.Framework: https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Framework\n",
    "\n",
    "class CustomFramework(Framework):\n",
    "    def __init__(\n",
    "        self,\n",
    "        entry_point,\n",
    "        framework_version=None,\n",
    "        py_version=None,\n",
    "        source_dir=None,\n",
    "        hyperparameters=None,\n",
    "        image_uri=None,\n",
    "        distribution=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(CustomFramework, self).__init__(\n",
    "            entry_point, source_dir, hyperparameters, image_uri=image_uri, **kwargs\n",
    "        )\n",
    "    \n",
    "    def _configure_distribution(self, distributions):\n",
    "        return None\n",
    "    \n",
    "    def create_model(\n",
    "        self,\n",
    "        model_server_workers=None,\n",
    "        role=None,\n",
    "        vpc_config_override=None,\n",
    "        entry_point=None,\n",
    "        source_dir=None,\n",
    "        dependencies=None,\n",
    "        image_uri=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53034e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_local_custom = {\n",
    "    'data': 'data_sm.yaml',\n",
    "    'cfg': 'yolov5s.yaml',\n",
    "    #'weights': 'weights/yolov5s.pt', # Transfer learning\n",
    "    'batch-size': 64,\n",
    "    'epochs': 1,\n",
    "    'project': '/opt/ml/model',\n",
    "    'workers': 0, # To avoid shm OOM issue\n",
    "    #'freeze': freeze, # For transfer learning, freeze all Layers except for the final output convolution layers.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_local_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88382531",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {source_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01761c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.local import LocalSession\n",
    "sagemaker_session = LocalSession()\n",
    "\n",
    "byoc_image_uri = '889750940888.dkr.ecr.us-east-1.amazonaws.com/sinjoonk-yolov5'\n",
    "instance_type = 'local_gpu'\n",
    "\n",
    "estimator_local_custom = CustomFramework(\n",
    "    image_uri=byoc_image_uri,\n",
    "    entry_point='train_sm.py',\n",
    "    source_dir=source_dir,\n",
    "    base_job_name='yolov5-on-sagemaker',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    instance_count=1,\n",
    "    instance_type='local_gpu',\n",
    "    volume_size=256,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters_local_custom,\n",
    "#     metric_definitions=metric_definitions,\n",
    "    max_run=3*60*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae39d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_dir = os.path.join(os.getcwd(), 'BCCD')\n",
    "\n",
    "inputs = {'yolov5_input': 'file://{}'.format(train_dir)}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd688ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "estimator_local_custom.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851efbac",
   "metadata": {},
   "source": [
    "## Managed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b679c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'yolov5-BCCD'\n",
    "instance_count = 1\n",
    "\n",
    "# instance_type = 'ml.g4dn.xlarge'\n",
    "# instance_type = 'ml.p3.2xlarge'\n",
    "instance_type = 'ml.p2.8xlarge'\n",
    "# instance_type = 'ml.m5.2xlarge' # Completed, pytorch-training-2021-11-03-09-12-19-947\n",
    "\n",
    "do_spot_training = True\n",
    "max_wait = 3*60*60\n",
    "max_run = 3*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae215b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_managed = {\n",
    "    'data': 'data_sm.yaml',\n",
    "    'cfg': 'yolov5s.yaml',\n",
    "#     'weights': 'weights/yolov5s.pt',\n",
    "    'batch-size': 128,\n",
    "    'epochs': 300,\n",
    "    'project': '/opt/ml/model',\n",
    "    'weights': 'weights/yolov5s.pt',\n",
    "    'workers': 8,\n",
    "#     'freeze': 24\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "byoc_image_uri = '889750940888.dkr.ecr.us-east-1.amazonaws.com/sinjoonk-yolov5'\n",
    "\n",
    "\n",
    "estimator_custom_managed = CustomFramework(image_uri=byoc_image_uri,\n",
    "                                           role=role,\n",
    "                                           entry_point='train_sm.py',\n",
    "                                           source_dir='yolov5',\n",
    "                                           instance_count=1, \n",
    "                                           instance_type=instance_type,\n",
    "                                           base_job_name='yolov5-on-sagemaker',\n",
    "                                           volume_size=256,\n",
    "                                           output_path=output_path,\n",
    "                                           checkpoint_s3_uri=checkpoint_s3_bucket,\n",
    "                                           hyperparameters=hyperparameters_managed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa29450",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'yolov5_input': s3_data_path}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5635f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, hyperparameters_managed, instance_type, instance_count, do_spot_training)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_custom_managed.fit(inputs=inputs,\n",
    "                      experiment_config={\n",
    "                          'TrialName': job_name,\n",
    "                          'TrialComponentDisplayName': job_name,\n",
    "                        },\n",
    "                      wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=estimator_custom_managed.latest_training_job.name\n",
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374a281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
